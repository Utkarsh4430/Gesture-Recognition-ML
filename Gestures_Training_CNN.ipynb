{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTatEvS0xjsQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries\n",
    "\n",
    "#image precessing\n",
    "import cv2\n",
    "#file handling\n",
    "import os\n",
    "#obvious\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#library to know the progress of for loops\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2rwyzt3-xjsW",
    "outputId": "b550a3de-4a78-4e13-e85a-62447fe6f28a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "#the path where the required files are\n",
    "x = []\n",
    "y = []\n",
    "IMG_SIZE = 64\n",
    "base_dir = 'Gestures'\n",
    "for i in tqdm(os.listdir(base_dir)):\n",
    "    path = os.path.join(base_dir,i)\n",
    "    for j in os.listdir(path):\n",
    "        img = cv2.imread(os.path.join(path,j),0)\n",
    "#         print(img.shape)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        img = img/255\n",
    "        if img is not None:\n",
    "            x.append(img)\n",
    "            y.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxwokIqKxjsb"
   },
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Gva0XBsJxjse",
    "outputId": "4e1b55d3-8b9d-4599-f5f9-dea47b6879ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5893, 64, 64), (5893,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sTA7dTzYxjsj",
    "outputId": "a975e71d-699b-40db-91c5-4e773fe2a151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5893, 5)\n"
     ]
    }
   ],
   "source": [
    "y = np_utils.to_categorical(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LoYHudQGxjsp"
   },
   "outputs": [],
   "source": [
    "x,y = shuffle(x,y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wuMEcU05xjsv",
    "outputId": "012d0fa5-8691-4bba-a5c1-8ad8b5bd2bcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5893, 64, 64, 1), (5893, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(x.shape[0],IMG_SIZE,IMG_SIZE,1)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkCk96DExjsz"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7YEDD-SPxjs3"
   },
   "outputs": [],
   "source": [
    "#multi classification model\n",
    "nClasses = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P-WFTRVZxjs7"
   },
   "outputs": [],
   "source": [
    "#constructing the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(IMG_SIZE,IMG_SIZE,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(nClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "id": "cBCrBfNDxjs_",
    "outputId": "8d8ddf29-097c-48c7-e955-b05291535396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 81925     \n",
      "=================================================================\n",
      "Total params: 100,741\n",
      "Trainable params: 100,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "yjGS1NnaxjtD",
    "outputId": "3fc5b0f0-5813-452d-f75f-96dfbc9a9aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5893/5893 [==============================] - ETA: 55s - loss: 1.6030 - acc: 0.22 - ETA: 44s - loss: 1.5917 - acc: 0.26 - ETA: 40s - loss: 1.5449 - acc: 0.31 - ETA: 37s - loss: 1.4885 - acc: 0.35 - ETA: 35s - loss: 1.4304 - acc: 0.41 - ETA: 33s - loss: 1.3749 - acc: 0.45 - ETA: 33s - loss: 1.3217 - acc: 0.49 - ETA: 31s - loss: 1.2520 - acc: 0.54 - ETA: 30s - loss: 1.2062 - acc: 0.57 - ETA: 29s - loss: 1.1570 - acc: 0.59 - ETA: 29s - loss: 1.1022 - acc: 0.61 - ETA: 28s - loss: 1.0612 - acc: 0.62 - ETA: 27s - loss: 1.0249 - acc: 0.64 - ETA: 26s - loss: 0.9783 - acc: 0.65 - ETA: 25s - loss: 0.9453 - acc: 0.66 - ETA: 25s - loss: 0.9384 - acc: 0.67 - ETA: 24s - loss: 0.9077 - acc: 0.68 - ETA: 23s - loss: 0.8792 - acc: 0.69 - ETA: 23s - loss: 0.8601 - acc: 0.69 - ETA: 22s - loss: 0.8309 - acc: 0.70 - ETA: 21s - loss: 0.8141 - acc: 0.71 - ETA: 21s - loss: 0.7981 - acc: 0.72 - ETA: 20s - loss: 0.7797 - acc: 0.72 - ETA: 19s - loss: 0.7639 - acc: 0.73 - ETA: 19s - loss: 0.7457 - acc: 0.74 - ETA: 18s - loss: 0.7343 - acc: 0.74 - ETA: 18s - loss: 0.7150 - acc: 0.75 - ETA: 17s - loss: 0.7029 - acc: 0.75 - ETA: 16s - loss: 0.6850 - acc: 0.76 - ETA: 16s - loss: 0.6688 - acc: 0.77 - ETA: 15s - loss: 0.6624 - acc: 0.77 - ETA: 15s - loss: 0.6520 - acc: 0.77 - ETA: 14s - loss: 0.6447 - acc: 0.77 - ETA: 14s - loss: 0.6311 - acc: 0.78 - ETA: 13s - loss: 0.6179 - acc: 0.78 - ETA: 12s - loss: 0.6081 - acc: 0.79 - ETA: 12s - loss: 0.6007 - acc: 0.79 - ETA: 11s - loss: 0.5914 - acc: 0.79 - ETA: 11s - loss: 0.5827 - acc: 0.80 - ETA: 10s - loss: 0.5717 - acc: 0.80 - ETA: 10s - loss: 0.5631 - acc: 0.81 - ETA: 9s - loss: 0.5533 - acc: 0.8133 - ETA: 8s - loss: 0.5457 - acc: 0.815 - ETA: 8s - loss: 0.5399 - acc: 0.817 - ETA: 7s - loss: 0.5321 - acc: 0.820 - ETA: 7s - loss: 0.5219 - acc: 0.824 - ETA: 6s - loss: 0.5133 - acc: 0.827 - ETA: 6s - loss: 0.5053 - acc: 0.830 - ETA: 5s - loss: 0.4977 - acc: 0.832 - ETA: 5s - loss: 0.4900 - acc: 0.835 - ETA: 4s - loss: 0.4835 - acc: 0.837 - ETA: 3s - loss: 0.4769 - acc: 0.840 - ETA: 3s - loss: 0.4710 - acc: 0.842 - ETA: 2s - loss: 0.4643 - acc: 0.844 - ETA: 2s - loss: 0.4576 - acc: 0.846 - ETA: 1s - loss: 0.4513 - acc: 0.849 - ETA: 1s - loss: 0.4463 - acc: 0.850 - ETA: 0s - loss: 0.4412 - acc: 0.852 - 33s 6ms/step - loss: 0.4353 - acc: 0.8547\n",
      "Epoch 2/5\n",
      "5893/5893 [==============================] - ETA: 33s - loss: 0.0955 - acc: 0.97 - ETA: 32s - loss: 0.0880 - acc: 0.97 - ETA: 31s - loss: 0.0809 - acc: 0.97 - ETA: 30s - loss: 0.0761 - acc: 0.98 - ETA: 29s - loss: 0.0720 - acc: 0.98 - ETA: 28s - loss: 0.0773 - acc: 0.98 - ETA: 28s - loss: 0.0790 - acc: 0.97 - ETA: 27s - loss: 0.0820 - acc: 0.97 - ETA: 27s - loss: 0.0807 - acc: 0.97 - ETA: 26s - loss: 0.0762 - acc: 0.98 - ETA: 26s - loss: 0.0765 - acc: 0.98 - ETA: 25s - loss: 0.0773 - acc: 0.97 - ETA: 24s - loss: 0.0775 - acc: 0.97 - ETA: 24s - loss: 0.0799 - acc: 0.97 - ETA: 23s - loss: 0.0771 - acc: 0.98 - ETA: 23s - loss: 0.0781 - acc: 0.97 - ETA: 22s - loss: 0.0758 - acc: 0.98 - ETA: 22s - loss: 0.0741 - acc: 0.98 - ETA: 21s - loss: 0.0721 - acc: 0.98 - ETA: 21s - loss: 0.0727 - acc: 0.98 - ETA: 20s - loss: 0.0707 - acc: 0.98 - ETA: 20s - loss: 0.0702 - acc: 0.98 - ETA: 19s - loss: 0.0692 - acc: 0.98 - ETA: 18s - loss: 0.0680 - acc: 0.98 - ETA: 18s - loss: 0.0678 - acc: 0.98 - ETA: 17s - loss: 0.0665 - acc: 0.98 - ETA: 17s - loss: 0.0650 - acc: 0.98 - ETA: 17s - loss: 0.0642 - acc: 0.98 - ETA: 16s - loss: 0.0633 - acc: 0.98 - ETA: 16s - loss: 0.0633 - acc: 0.98 - ETA: 15s - loss: 0.0619 - acc: 0.98 - ETA: 14s - loss: 0.0607 - acc: 0.98 - ETA: 14s - loss: 0.0598 - acc: 0.98 - ETA: 13s - loss: 0.0587 - acc: 0.98 - ETA: 13s - loss: 0.0578 - acc: 0.98 - ETA: 12s - loss: 0.0570 - acc: 0.98 - ETA: 12s - loss: 0.0560 - acc: 0.98 - ETA: 11s - loss: 0.0556 - acc: 0.98 - ETA: 11s - loss: 0.0551 - acc: 0.98 - ETA: 10s - loss: 0.0546 - acc: 0.98 - ETA: 9s - loss: 0.0545 - acc: 0.9859 - ETA: 9s - loss: 0.0537 - acc: 0.986 - ETA: 8s - loss: 0.0527 - acc: 0.986 - ETA: 8s - loss: 0.0527 - acc: 0.986 - ETA: 7s - loss: 0.0520 - acc: 0.986 - ETA: 7s - loss: 0.0517 - acc: 0.986 - ETA: 6s - loss: 0.0511 - acc: 0.986 - ETA: 6s - loss: 0.0505 - acc: 0.987 - ETA: 5s - loss: 0.0499 - acc: 0.987 - ETA: 4s - loss: 0.0495 - acc: 0.987 - ETA: 4s - loss: 0.0492 - acc: 0.987 - ETA: 3s - loss: 0.0489 - acc: 0.987 - ETA: 3s - loss: 0.0482 - acc: 0.987 - ETA: 2s - loss: 0.0474 - acc: 0.988 - ETA: 2s - loss: 0.0468 - acc: 0.988 - ETA: 1s - loss: 0.0466 - acc: 0.988 - ETA: 1s - loss: 0.0464 - acc: 0.988 - ETA: 0s - loss: 0.0457 - acc: 0.988 - 33s 6ms/step - loss: 0.0453 - acc: 0.9886\n",
      "Epoch 3/5\n",
      "5893/5893 [==============================] - ETA: 38s - loss: 0.0143 - acc: 1.00 - ETA: 37s - loss: 0.0124 - acc: 1.00 - ETA: 38s - loss: 0.0146 - acc: 0.99 - ETA: 36s - loss: 0.0132 - acc: 0.99 - ETA: 34s - loss: 0.0154 - acc: 0.99 - ETA: 32s - loss: 0.0159 - acc: 0.99 - ETA: 31s - loss: 0.0171 - acc: 0.99 - ETA: 30s - loss: 0.0183 - acc: 0.99 - ETA: 29s - loss: 0.0188 - acc: 0.99 - ETA: 28s - loss: 0.0180 - acc: 0.99 - ETA: 28s - loss: 0.0168 - acc: 0.99 - ETA: 28s - loss: 0.0162 - acc: 0.99 - ETA: 27s - loss: 0.0156 - acc: 0.99 - ETA: 27s - loss: 0.0166 - acc: 0.99 - ETA: 26s - loss: 0.0161 - acc: 0.99 - ETA: 25s - loss: 0.0160 - acc: 0.99 - ETA: 24s - loss: 0.0157 - acc: 0.99 - ETA: 24s - loss: 0.0153 - acc: 0.99 - ETA: 23s - loss: 0.0150 - acc: 0.99 - ETA: 22s - loss: 0.0147 - acc: 0.99 - ETA: 22s - loss: 0.0144 - acc: 0.99 - ETA: 21s - loss: 0.0157 - acc: 0.99 - ETA: 21s - loss: 0.0153 - acc: 0.99 - ETA: 20s - loss: 0.0151 - acc: 0.99 - ETA: 20s - loss: 0.0150 - acc: 0.99 - ETA: 19s - loss: 0.0146 - acc: 0.99 - ETA: 18s - loss: 0.0150 - acc: 0.99 - ETA: 18s - loss: 0.0150 - acc: 0.99 - ETA: 17s - loss: 0.0148 - acc: 0.99 - ETA: 16s - loss: 0.0147 - acc: 0.99 - ETA: 16s - loss: 0.0145 - acc: 0.99 - ETA: 15s - loss: 0.0142 - acc: 0.99 - ETA: 15s - loss: 0.0140 - acc: 0.99 - ETA: 14s - loss: 0.0138 - acc: 0.99 - ETA: 14s - loss: 0.0140 - acc: 0.99 - ETA: 13s - loss: 0.0138 - acc: 0.99 - ETA: 12s - loss: 0.0140 - acc: 0.99 - ETA: 12s - loss: 0.0139 - acc: 0.99 - ETA: 11s - loss: 0.0139 - acc: 0.99 - ETA: 11s - loss: 0.0137 - acc: 0.99 - ETA: 10s - loss: 0.0136 - acc: 0.99 - ETA: 9s - loss: 0.0135 - acc: 0.9981 - ETA: 9s - loss: 0.0134 - acc: 0.998 - ETA: 8s - loss: 0.0132 - acc: 0.998 - ETA: 8s - loss: 0.0134 - acc: 0.998 - ETA: 7s - loss: 0.0133 - acc: 0.998 - ETA: 6s - loss: 0.0132 - acc: 0.998 - ETA: 6s - loss: 0.0132 - acc: 0.997 - ETA: 5s - loss: 0.0132 - acc: 0.998 - ETA: 5s - loss: 0.0130 - acc: 0.998 - ETA: 4s - loss: 0.0128 - acc: 0.998 - ETA: 4s - loss: 0.0126 - acc: 0.998 - ETA: 3s - loss: 0.0124 - acc: 0.998 - ETA: 2s - loss: 0.0122 - acc: 0.998 - ETA: 2s - loss: 0.0124 - acc: 0.998 - ETA: 1s - loss: 0.0123 - acc: 0.998 - ETA: 1s - loss: 0.0122 - acc: 0.998 - ETA: 0s - loss: 0.0122 - acc: 0.998 - 34s 6ms/step - loss: 0.0120 - acc: 0.9981\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5893/5893 [==============================] - ETA: 31s - loss: 0.0031 - acc: 1.00 - ETA: 30s - loss: 0.0053 - acc: 1.00 - ETA: 31s - loss: 0.0059 - acc: 1.00 - ETA: 32s - loss: 0.0068 - acc: 1.00 - ETA: 32s - loss: 0.0062 - acc: 1.00 - ETA: 31s - loss: 0.0056 - acc: 1.00 - ETA: 30s - loss: 0.0058 - acc: 1.00 - ETA: 29s - loss: 0.0054 - acc: 1.00 - ETA: 28s - loss: 0.0058 - acc: 1.00 - ETA: 28s - loss: 0.0067 - acc: 1.00 - ETA: 27s - loss: 0.0069 - acc: 1.00 - ETA: 26s - loss: 0.0066 - acc: 1.00 - ETA: 26s - loss: 0.0063 - acc: 1.00 - ETA: 25s - loss: 0.0063 - acc: 1.00 - ETA: 25s - loss: 0.0069 - acc: 1.00 - ETA: 25s - loss: 0.0067 - acc: 1.00 - ETA: 24s - loss: 0.0065 - acc: 1.00 - ETA: 24s - loss: 0.0064 - acc: 1.00 - ETA: 23s - loss: 0.0062 - acc: 1.00 - ETA: 22s - loss: 0.0059 - acc: 1.00 - ETA: 22s - loss: 0.0058 - acc: 1.00 - ETA: 21s - loss: 0.0058 - acc: 1.00 - ETA: 20s - loss: 0.0057 - acc: 1.00 - ETA: 20s - loss: 0.0055 - acc: 1.00 - ETA: 19s - loss: 0.0054 - acc: 1.00 - ETA: 19s - loss: 0.0053 - acc: 1.00 - ETA: 18s - loss: 0.0052 - acc: 1.00 - ETA: 18s - loss: 0.0052 - acc: 1.00 - ETA: 17s - loss: 0.0050 - acc: 1.00 - ETA: 16s - loss: 0.0051 - acc: 1.00 - ETA: 16s - loss: 0.0051 - acc: 1.00 - ETA: 15s - loss: 0.0052 - acc: 1.00 - ETA: 15s - loss: 0.0051 - acc: 1.00 - ETA: 14s - loss: 0.0052 - acc: 1.00 - ETA: 14s - loss: 0.0051 - acc: 1.00 - ETA: 13s - loss: 0.0050 - acc: 1.00 - ETA: 12s - loss: 0.0050 - acc: 1.00 - ETA: 12s - loss: 0.0050 - acc: 1.00 - ETA: 11s - loss: 0.0049 - acc: 1.00 - ETA: 11s - loss: 0.0048 - acc: 1.00 - ETA: 10s - loss: 0.0048 - acc: 1.00 - ETA: 10s - loss: 0.0050 - acc: 1.00 - ETA: 9s - loss: 0.0049 - acc: 1.0000 - ETA: 8s - loss: 0.0048 - acc: 1.000 - ETA: 8s - loss: 0.0047 - acc: 1.000 - ETA: 7s - loss: 0.0050 - acc: 0.999 - ETA: 7s - loss: 0.0050 - acc: 0.999 - ETA: 6s - loss: 0.0049 - acc: 0.999 - ETA: 5s - loss: 0.0051 - acc: 0.999 - ETA: 5s - loss: 0.0051 - acc: 0.999 - ETA: 4s - loss: 0.0050 - acc: 0.999 - ETA: 4s - loss: 0.0050 - acc: 0.999 - ETA: 3s - loss: 0.0049 - acc: 0.999 - ETA: 2s - loss: 0.0050 - acc: 0.999 - ETA: 2s - loss: 0.0049 - acc: 0.999 - ETA: 1s - loss: 0.0049 - acc: 0.999 - ETA: 1s - loss: 0.0049 - acc: 0.999 - ETA: 0s - loss: 0.0049 - acc: 0.999 - 35s 6ms/step - loss: 0.0049 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "5893/5893 [==============================] - ETA: 36s - loss: 0.0027 - acc: 1.00 - ETA: 36s - loss: 0.0065 - acc: 1.00 - ETA: 35s - loss: 0.0047 - acc: 1.00 - ETA: 35s - loss: 0.0046 - acc: 1.00 - ETA: 34s - loss: 0.0041 - acc: 1.00 - ETA: 32s - loss: 0.0037 - acc: 1.00 - ETA: 31s - loss: 0.0037 - acc: 1.00 - ETA: 30s - loss: 0.0037 - acc: 1.00 - ETA: 29s - loss: 0.0040 - acc: 1.00 - ETA: 28s - loss: 0.0039 - acc: 1.00 - ETA: 28s - loss: 0.0040 - acc: 1.00 - ETA: 28s - loss: 0.0037 - acc: 1.00 - ETA: 27s - loss: 0.0036 - acc: 1.00 - ETA: 27s - loss: 0.0035 - acc: 1.00 - ETA: 26s - loss: 0.0034 - acc: 1.00 - ETA: 26s - loss: 0.0033 - acc: 1.00 - ETA: 25s - loss: 0.0032 - acc: 1.00 - ETA: 24s - loss: 0.0031 - acc: 1.00 - ETA: 23s - loss: 0.0030 - acc: 1.00 - ETA: 23s - loss: 0.0030 - acc: 1.00 - ETA: 22s - loss: 0.0029 - acc: 1.00 - ETA: 21s - loss: 0.0028 - acc: 1.00 - ETA: 21s - loss: 0.0027 - acc: 1.00 - ETA: 20s - loss: 0.0027 - acc: 1.00 - ETA: 20s - loss: 0.0027 - acc: 1.00 - ETA: 19s - loss: 0.0026 - acc: 1.00 - ETA: 19s - loss: 0.0026 - acc: 1.00 - ETA: 18s - loss: 0.0026 - acc: 1.00 - ETA: 17s - loss: 0.0026 - acc: 1.00 - ETA: 17s - loss: 0.0026 - acc: 1.00 - ETA: 16s - loss: 0.0025 - acc: 1.00 - ETA: 15s - loss: 0.0026 - acc: 1.00 - ETA: 15s - loss: 0.0026 - acc: 1.00 - ETA: 14s - loss: 0.0026 - acc: 1.00 - ETA: 14s - loss: 0.0025 - acc: 1.00 - ETA: 13s - loss: 0.0025 - acc: 1.00 - ETA: 13s - loss: 0.0025 - acc: 1.00 - ETA: 12s - loss: 0.0025 - acc: 1.00 - ETA: 11s - loss: 0.0024 - acc: 1.00 - ETA: 11s - loss: 0.0024 - acc: 1.00 - ETA: 10s - loss: 0.0025 - acc: 1.00 - ETA: 10s - loss: 0.0025 - acc: 1.00 - ETA: 9s - loss: 0.0024 - acc: 1.0000 - ETA: 8s - loss: 0.0024 - acc: 1.000 - ETA: 8s - loss: 0.0024 - acc: 1.000 - ETA: 7s - loss: 0.0023 - acc: 1.000 - ETA: 7s - loss: 0.0024 - acc: 1.000 - ETA: 6s - loss: 0.0024 - acc: 1.000 - ETA: 5s - loss: 0.0023 - acc: 1.000 - ETA: 5s - loss: 0.0023 - acc: 1.000 - ETA: 4s - loss: 0.0023 - acc: 1.000 - ETA: 4s - loss: 0.0023 - acc: 1.000 - ETA: 3s - loss: 0.0023 - acc: 1.000 - ETA: 2s - loss: 0.0023 - acc: 1.000 - ETA: 2s - loss: 0.0023 - acc: 1.000 - ETA: 1s - loss: 0.0023 - acc: 1.000 - ETA: 1s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - 35s 6ms/step - loss: 0.0022 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17e3de055f8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs =5,batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qTRzXBYfxjtK",
    "outputId": "a42815b8-6763-438f-b37a-2600afb68e53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5893/5893 [==============================] - ETA: 22 - ETA: 18 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 13s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "loss2, acc2 = model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0lYHDWY-NeI"
   },
   "outputs": [],
   "source": [
    "model.save(\"Gesture-model-saved.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Gestures-Training-CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
