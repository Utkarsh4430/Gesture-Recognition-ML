{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTatEvS0xjsQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries\n",
    "\n",
    "#image precessing\n",
    "import cv2\n",
    "#file handling\n",
    "import os\n",
    "#obvious\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#library to know the progress of for loops\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2rwyzt3-xjsW",
    "outputId": "b550a3de-4a78-4e13-e85a-62447fe6f28a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "#the path where the required files are\n",
    "x = []\n",
    "y = []\n",
    "IMG_SIZE = 64\n",
    "base_dir = 'Gestures'\n",
    "for i in tqdm(os.listdir(base_dir)):\n",
    "    path = os.path.join(base_dir,i)\n",
    "    for j in os.listdir(path):\n",
    "        img = cv2.imread(os.path.join(path,j),0)\n",
    "#         print(img.shape)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        img = img/255\n",
    "        if img is not None:\n",
    "            x.append(img)\n",
    "            y.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxwokIqKxjsb"
   },
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Gva0XBsJxjse",
    "outputId": "4e1b55d3-8b9d-4599-f5f9-dea47b6879ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7093, 64, 64), (7093,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sTA7dTzYxjsj",
    "outputId": "a975e71d-699b-40db-91c5-4e773fe2a151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7093, 6)\n"
     ]
    }
   ],
   "source": [
    "y = np_utils.to_categorical(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LoYHudQGxjsp"
   },
   "outputs": [],
   "source": [
    "x,y = shuffle(x,y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wuMEcU05xjsv",
    "outputId": "012d0fa5-8691-4bba-a5c1-8ad8b5bd2bcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7093, 64, 64, 1), (7093, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(x.shape[0],IMG_SIZE,IMG_SIZE,1)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkCk96DExjsz"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7YEDD-SPxjs3"
   },
   "outputs": [],
   "source": [
    "#multi classification model\n",
    "nClasses = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P-WFTRVZxjs7"
   },
   "outputs": [],
   "source": [
    "#constructing the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(IMG_SIZE,IMG_SIZE,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(nClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "id": "cBCrBfNDxjs_",
    "outputId": "8d8ddf29-097c-48c7-e955-b05291535396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 98310     \n",
      "=================================================================\n",
      "Total params: 117,126\n",
      "Trainable params: 117,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "yjGS1NnaxjtD",
    "outputId": "3fc5b0f0-5813-452d-f75f-96dfbc9a9aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7093/7093 [==============================] - ETA: 1:09 - loss: 1.8016 - acc: 0.190 - ETA: 1:00 - loss: 1.7178 - acc: 0.295 - ETA: 56s - loss: 1.6228 - acc: 0.376 - ETA: 54s - loss: 1.5594 - acc: 0.41 - ETA: 51s - loss: 1.5095 - acc: 0.44 - ETA: 49s - loss: 1.4560 - acc: 0.48 - ETA: 47s - loss: 1.3819 - acc: 0.52 - ETA: 45s - loss: 1.3250 - acc: 0.54 - ETA: 43s - loss: 1.2677 - acc: 0.57 - ETA: 42s - loss: 1.2197 - acc: 0.59 - ETA: 40s - loss: 1.1642 - acc: 0.61 - ETA: 39s - loss: 1.1075 - acc: 0.64 - ETA: 38s - loss: 1.0582 - acc: 0.65 - ETA: 37s - loss: 1.0175 - acc: 0.66 - ETA: 36s - loss: 0.9886 - acc: 0.67 - ETA: 35s - loss: 0.9631 - acc: 0.68 - ETA: 34s - loss: 0.9679 - acc: 0.69 - ETA: 34s - loss: 0.9497 - acc: 0.69 - ETA: 33s - loss: 0.9233 - acc: 0.70 - ETA: 32s - loss: 0.9054 - acc: 0.71 - ETA: 31s - loss: 0.8762 - acc: 0.72 - ETA: 31s - loss: 0.8519 - acc: 0.72 - ETA: 30s - loss: 0.8389 - acc: 0.73 - ETA: 29s - loss: 0.8187 - acc: 0.74 - ETA: 29s - loss: 0.7971 - acc: 0.74 - ETA: 28s - loss: 0.7811 - acc: 0.75 - ETA: 27s - loss: 0.7663 - acc: 0.75 - ETA: 26s - loss: 0.7486 - acc: 0.76 - ETA: 26s - loss: 0.7347 - acc: 0.76 - ETA: 25s - loss: 0.7199 - acc: 0.77 - ETA: 24s - loss: 0.7108 - acc: 0.77 - ETA: 24s - loss: 0.6967 - acc: 0.77 - ETA: 23s - loss: 0.6830 - acc: 0.78 - ETA: 22s - loss: 0.6691 - acc: 0.78 - ETA: 22s - loss: 0.6557 - acc: 0.79 - ETA: 21s - loss: 0.6425 - acc: 0.79 - ETA: 20s - loss: 0.6314 - acc: 0.79 - ETA: 20s - loss: 0.6228 - acc: 0.80 - ETA: 19s - loss: 0.6123 - acc: 0.80 - ETA: 18s - loss: 0.6005 - acc: 0.80 - ETA: 18s - loss: 0.5889 - acc: 0.81 - ETA: 17s - loss: 0.5807 - acc: 0.81 - ETA: 17s - loss: 0.5710 - acc: 0.81 - ETA: 16s - loss: 0.5626 - acc: 0.82 - ETA: 15s - loss: 0.5545 - acc: 0.82 - ETA: 15s - loss: 0.5474 - acc: 0.82 - ETA: 14s - loss: 0.5396 - acc: 0.82 - ETA: 13s - loss: 0.5357 - acc: 0.83 - ETA: 13s - loss: 0.5293 - acc: 0.83 - ETA: 12s - loss: 0.5245 - acc: 0.83 - ETA: 12s - loss: 0.5169 - acc: 0.83 - ETA: 11s - loss: 0.5118 - acc: 0.83 - ETA: 10s - loss: 0.5060 - acc: 0.83 - ETA: 10s - loss: 0.5017 - acc: 0.84 - ETA: 9s - loss: 0.4943 - acc: 0.8436 - ETA: 9s - loss: 0.4874 - acc: 0.845 - ETA: 8s - loss: 0.4819 - acc: 0.847 - ETA: 7s - loss: 0.4765 - acc: 0.849 - ETA: 7s - loss: 0.4701 - acc: 0.851 - ETA: 6s - loss: 0.4641 - acc: 0.853 - ETA: 6s - loss: 0.4575 - acc: 0.855 - ETA: 5s - loss: 0.4518 - acc: 0.857 - ETA: 4s - loss: 0.4466 - acc: 0.858 - ETA: 4s - loss: 0.4413 - acc: 0.860 - ETA: 3s - loss: 0.4367 - acc: 0.862 - ETA: 2s - loss: 0.4324 - acc: 0.863 - ETA: 2s - loss: 0.4274 - acc: 0.864 - ETA: 1s - loss: 0.4224 - acc: 0.866 - ETA: 1s - loss: 0.4178 - acc: 0.867 - ETA: 0s - loss: 0.4134 - acc: 0.869 - 43s 6ms/step - loss: 0.4097 - acc: 0.8704\n",
      "Epoch 2/5\n",
      "7093/7093 [==============================] - ETA: 40s - loss: 0.0500 - acc: 0.99 - ETA: 39s - loss: 0.0662 - acc: 0.98 - ETA: 39s - loss: 0.0677 - acc: 0.98 - ETA: 38s - loss: 0.0692 - acc: 0.98 - ETA: 38s - loss: 0.0720 - acc: 0.98 - ETA: 37s - loss: 0.0687 - acc: 0.98 - ETA: 37s - loss: 0.0733 - acc: 0.98 - ETA: 36s - loss: 0.0748 - acc: 0.98 - ETA: 35s - loss: 0.0742 - acc: 0.98 - ETA: 35s - loss: 0.0731 - acc: 0.98 - ETA: 34s - loss: 0.0701 - acc: 0.98 - ETA: 34s - loss: 0.0678 - acc: 0.98 - ETA: 33s - loss: 0.0677 - acc: 0.98 - ETA: 33s - loss: 0.0647 - acc: 0.98 - ETA: 32s - loss: 0.0626 - acc: 0.98 - ETA: 31s - loss: 0.0618 - acc: 0.98 - ETA: 31s - loss: 0.0592 - acc: 0.98 - ETA: 30s - loss: 0.0593 - acc: 0.98 - ETA: 30s - loss: 0.0612 - acc: 0.98 - ETA: 29s - loss: 0.0612 - acc: 0.98 - ETA: 29s - loss: 0.0593 - acc: 0.98 - ETA: 28s - loss: 0.0575 - acc: 0.98 - ETA: 28s - loss: 0.0562 - acc: 0.98 - ETA: 27s - loss: 0.0553 - acc: 0.98 - ETA: 26s - loss: 0.0556 - acc: 0.98 - ETA: 26s - loss: 0.0562 - acc: 0.98 - ETA: 25s - loss: 0.0546 - acc: 0.98 - ETA: 25s - loss: 0.0536 - acc: 0.98 - ETA: 24s - loss: 0.0527 - acc: 0.98 - ETA: 24s - loss: 0.0524 - acc: 0.98 - ETA: 23s - loss: 0.0514 - acc: 0.98 - ETA: 23s - loss: 0.0512 - acc: 0.98 - ETA: 22s - loss: 0.0510 - acc: 0.98 - ETA: 22s - loss: 0.0502 - acc: 0.98 - ETA: 21s - loss: 0.0497 - acc: 0.98 - ETA: 20s - loss: 0.0493 - acc: 0.98 - ETA: 20s - loss: 0.0496 - acc: 0.98 - ETA: 19s - loss: 0.0487 - acc: 0.98 - ETA: 18s - loss: 0.0487 - acc: 0.98 - ETA: 18s - loss: 0.0484 - acc: 0.98 - ETA: 17s - loss: 0.0480 - acc: 0.98 - ETA: 17s - loss: 0.0486 - acc: 0.98 - ETA: 16s - loss: 0.0486 - acc: 0.98 - ETA: 16s - loss: 0.0480 - acc: 0.98 - ETA: 15s - loss: 0.0474 - acc: 0.98 - ETA: 14s - loss: 0.0471 - acc: 0.98 - ETA: 14s - loss: 0.0466 - acc: 0.98 - ETA: 13s - loss: 0.0463 - acc: 0.98 - ETA: 13s - loss: 0.0457 - acc: 0.98 - ETA: 12s - loss: 0.0453 - acc: 0.98 - ETA: 11s - loss: 0.0450 - acc: 0.98 - ETA: 11s - loss: 0.0444 - acc: 0.98 - ETA: 10s - loss: 0.0438 - acc: 0.98 - ETA: 10s - loss: 0.0433 - acc: 0.98 - ETA: 9s - loss: 0.0430 - acc: 0.9878 - ETA: 8s - loss: 0.0434 - acc: 0.987 - ETA: 8s - loss: 0.0432 - acc: 0.987 - ETA: 7s - loss: 0.0429 - acc: 0.987 - ETA: 7s - loss: 0.0424 - acc: 0.988 - ETA: 6s - loss: 0.0422 - acc: 0.988 - ETA: 5s - loss: 0.0419 - acc: 0.988 - ETA: 5s - loss: 0.0418 - acc: 0.988 - ETA: 4s - loss: 0.0413 - acc: 0.988 - ETA: 4s - loss: 0.0409 - acc: 0.988 - ETA: 3s - loss: 0.0410 - acc: 0.988 - ETA: 2s - loss: 0.0407 - acc: 0.988 - ETA: 2s - loss: 0.0402 - acc: 0.988 - ETA: 1s - loss: 0.0398 - acc: 0.989 - ETA: 1s - loss: 0.0397 - acc: 0.989 - ETA: 0s - loss: 0.0393 - acc: 0.989 - 43s 6ms/step - loss: 0.0390 - acc: 0.9893\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7093/7093 [==============================] - ETA: 40s - loss: 0.0153 - acc: 1.00 - ETA: 39s - loss: 0.0100 - acc: 1.00 - ETA: 39s - loss: 0.0111 - acc: 1.00 - ETA: 38s - loss: 0.0116 - acc: 1.00 - ETA: 38s - loss: 0.0106 - acc: 1.00 - ETA: 37s - loss: 0.0128 - acc: 0.99 - ETA: 37s - loss: 0.0144 - acc: 0.99 - ETA: 36s - loss: 0.0135 - acc: 0.99 - ETA: 36s - loss: 0.0153 - acc: 0.99 - ETA: 35s - loss: 0.0150 - acc: 0.99 - ETA: 35s - loss: 0.0146 - acc: 0.99 - ETA: 34s - loss: 0.0137 - acc: 0.99 - ETA: 33s - loss: 0.0138 - acc: 0.99 - ETA: 33s - loss: 0.0140 - acc: 0.99 - ETA: 32s - loss: 0.0143 - acc: 0.99 - ETA: 32s - loss: 0.0138 - acc: 0.99 - ETA: 31s - loss: 0.0138 - acc: 0.99 - ETA: 31s - loss: 0.0135 - acc: 0.99 - ETA: 30s - loss: 0.0134 - acc: 0.99 - ETA: 29s - loss: 0.0135 - acc: 0.99 - ETA: 29s - loss: 0.0133 - acc: 0.99 - ETA: 28s - loss: 0.0130 - acc: 0.99 - ETA: 28s - loss: 0.0133 - acc: 0.99 - ETA: 27s - loss: 0.0135 - acc: 0.99 - ETA: 26s - loss: 0.0137 - acc: 0.99 - ETA: 26s - loss: 0.0134 - acc: 0.99 - ETA: 25s - loss: 0.0135 - acc: 0.99 - ETA: 25s - loss: 0.0135 - acc: 0.99 - ETA: 24s - loss: 0.0132 - acc: 0.99 - ETA: 24s - loss: 0.0129 - acc: 0.99 - ETA: 23s - loss: 0.0127 - acc: 0.99 - ETA: 22s - loss: 0.0126 - acc: 0.99 - ETA: 22s - loss: 0.0124 - acc: 0.99 - ETA: 21s - loss: 0.0124 - acc: 0.99 - ETA: 21s - loss: 0.0122 - acc: 0.99 - ETA: 20s - loss: 0.0121 - acc: 0.99 - ETA: 19s - loss: 0.0119 - acc: 0.99 - ETA: 19s - loss: 0.0117 - acc: 0.99 - ETA: 18s - loss: 0.0120 - acc: 0.99 - ETA: 18s - loss: 0.0129 - acc: 0.99 - ETA: 17s - loss: 0.0127 - acc: 0.99 - ETA: 16s - loss: 0.0126 - acc: 0.99 - ETA: 16s - loss: 0.0127 - acc: 0.99 - ETA: 15s - loss: 0.0126 - acc: 0.99 - ETA: 15s - loss: 0.0124 - acc: 0.99 - ETA: 14s - loss: 0.0123 - acc: 0.99 - ETA: 14s - loss: 0.0122 - acc: 0.99 - ETA: 13s - loss: 0.0120 - acc: 0.99 - ETA: 12s - loss: 0.0120 - acc: 0.99 - ETA: 12s - loss: 0.0119 - acc: 0.99 - ETA: 11s - loss: 0.0118 - acc: 0.99 - ETA: 11s - loss: 0.0117 - acc: 0.99 - ETA: 10s - loss: 0.0116 - acc: 0.99 - ETA: 9s - loss: 0.0116 - acc: 0.9980 - ETA: 9s - loss: 0.0117 - acc: 0.997 - ETA: 8s - loss: 0.0121 - acc: 0.997 - ETA: 8s - loss: 0.0119 - acc: 0.997 - ETA: 7s - loss: 0.0119 - acc: 0.997 - ETA: 7s - loss: 0.0118 - acc: 0.997 - ETA: 6s - loss: 0.0117 - acc: 0.997 - ETA: 5s - loss: 0.0118 - acc: 0.997 - ETA: 5s - loss: 0.0117 - acc: 0.997 - ETA: 4s - loss: 0.0116 - acc: 0.997 - ETA: 4s - loss: 0.0116 - acc: 0.997 - ETA: 3s - loss: 0.0114 - acc: 0.997 - ETA: 2s - loss: 0.0114 - acc: 0.997 - ETA: 2s - loss: 0.0114 - acc: 0.997 - ETA: 1s - loss: 0.0113 - acc: 0.997 - ETA: 1s - loss: 0.0112 - acc: 0.998 - ETA: 0s - loss: 0.0111 - acc: 0.998 - 42s 6ms/step - loss: 0.0111 - acc: 0.9980\n",
      "Epoch 4/5\n",
      "7093/7093 [==============================] - ETA: 43s - loss: 0.0059 - acc: 1.00 - ETA: 41s - loss: 0.0046 - acc: 1.00 - ETA: 41s - loss: 0.0040 - acc: 1.00 - ETA: 39s - loss: 0.0040 - acc: 1.00 - ETA: 39s - loss: 0.0039 - acc: 1.00 - ETA: 38s - loss: 0.0035 - acc: 1.00 - ETA: 38s - loss: 0.0036 - acc: 1.00 - ETA: 37s - loss: 0.0041 - acc: 1.00 - ETA: 37s - loss: 0.0038 - acc: 1.00 - ETA: 36s - loss: 0.0036 - acc: 1.00 - ETA: 36s - loss: 0.0034 - acc: 1.00 - ETA: 35s - loss: 0.0036 - acc: 1.00 - ETA: 35s - loss: 0.0036 - acc: 1.00 - ETA: 34s - loss: 0.0039 - acc: 1.00 - ETA: 33s - loss: 0.0037 - acc: 1.00 - ETA: 33s - loss: 0.0036 - acc: 1.00 - ETA: 32s - loss: 0.0042 - acc: 1.00 - ETA: 31s - loss: 0.0041 - acc: 1.00 - ETA: 31s - loss: 0.0042 - acc: 1.00 - ETA: 30s - loss: 0.0042 - acc: 1.00 - ETA: 30s - loss: 0.0044 - acc: 1.00 - ETA: 29s - loss: 0.0043 - acc: 1.00 - ETA: 28s - loss: 0.0042 - acc: 1.00 - ETA: 28s - loss: 0.0042 - acc: 1.00 - ETA: 27s - loss: 0.0042 - acc: 1.00 - ETA: 26s - loss: 0.0043 - acc: 1.00 - ETA: 26s - loss: 0.0042 - acc: 1.00 - ETA: 25s - loss: 0.0042 - acc: 1.00 - ETA: 25s - loss: 0.0041 - acc: 1.00 - ETA: 24s - loss: 0.0043 - acc: 0.99 - ETA: 23s - loss: 0.0043 - acc: 0.99 - ETA: 23s - loss: 0.0043 - acc: 0.99 - ETA: 22s - loss: 0.0042 - acc: 0.99 - ETA: 21s - loss: 0.0041 - acc: 0.99 - ETA: 21s - loss: 0.0044 - acc: 0.99 - ETA: 20s - loss: 0.0044 - acc: 0.99 - ETA: 20s - loss: 0.0043 - acc: 0.99 - ETA: 19s - loss: 0.0042 - acc: 0.99 - ETA: 18s - loss: 0.0042 - acc: 0.99 - ETA: 18s - loss: 0.0044 - acc: 0.99 - ETA: 17s - loss: 0.0045 - acc: 0.99 - ETA: 17s - loss: 0.0046 - acc: 0.99 - ETA: 16s - loss: 0.0045 - acc: 0.99 - ETA: 15s - loss: 0.0046 - acc: 0.99 - ETA: 15s - loss: 0.0046 - acc: 0.99 - ETA: 14s - loss: 0.0046 - acc: 0.99 - ETA: 14s - loss: 0.0046 - acc: 0.99 - ETA: 13s - loss: 0.0048 - acc: 0.99 - ETA: 12s - loss: 0.0048 - acc: 0.99 - ETA: 12s - loss: 0.0048 - acc: 0.99 - ETA: 11s - loss: 0.0048 - acc: 0.99 - ETA: 11s - loss: 0.0048 - acc: 0.99 - ETA: 10s - loss: 0.0047 - acc: 0.99 - ETA: 10s - loss: 0.0047 - acc: 0.99 - ETA: 9s - loss: 0.0046 - acc: 0.9996 - ETA: 8s - loss: 0.0046 - acc: 0.999 - ETA: 8s - loss: 0.0045 - acc: 0.999 - ETA: 7s - loss: 0.0045 - acc: 0.999 - ETA: 7s - loss: 0.0045 - acc: 0.999 - ETA: 6s - loss: 0.0046 - acc: 0.999 - ETA: 5s - loss: 0.0047 - acc: 0.999 - ETA: 5s - loss: 0.0047 - acc: 0.999 - ETA: 4s - loss: 0.0047 - acc: 0.999 - ETA: 4s - loss: 0.0048 - acc: 0.999 - ETA: 3s - loss: 0.0048 - acc: 0.999 - ETA: 2s - loss: 0.0047 - acc: 0.999 - ETA: 2s - loss: 0.0050 - acc: 0.999 - ETA: 1s - loss: 0.0049 - acc: 0.999 - ETA: 1s - loss: 0.0049 - acc: 0.999 - ETA: 0s - loss: 0.0049 - acc: 0.999 - 42s 6ms/step - loss: 0.0050 - acc: 0.9996\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7093/7093 [==============================] - ETA: 41s - loss: 0.0073 - acc: 1.00 - ETA: 41s - loss: 0.0084 - acc: 1.00 - ETA: 40s - loss: 0.0067 - acc: 1.00 - ETA: 39s - loss: 0.0067 - acc: 1.00 - ETA: 39s - loss: 0.0056 - acc: 1.00 - ETA: 38s - loss: 0.0055 - acc: 1.00 - ETA: 37s - loss: 0.0060 - acc: 1.00 - ETA: 37s - loss: 0.0055 - acc: 1.00 - ETA: 36s - loss: 0.0062 - acc: 1.00 - ETA: 36s - loss: 0.0062 - acc: 1.00 - ETA: 35s - loss: 0.0058 - acc: 1.00 - ETA: 34s - loss: 0.0055 - acc: 1.00 - ETA: 34s - loss: 0.0052 - acc: 1.00 - ETA: 33s - loss: 0.0049 - acc: 1.00 - ETA: 32s - loss: 0.0048 - acc: 1.00 - ETA: 32s - loss: 0.0047 - acc: 1.00 - ETA: 31s - loss: 0.0046 - acc: 1.00 - ETA: 31s - loss: 0.0044 - acc: 1.00 - ETA: 30s - loss: 0.0043 - acc: 1.00 - ETA: 29s - loss: 0.0043 - acc: 1.00 - ETA: 29s - loss: 0.0043 - acc: 1.00 - ETA: 28s - loss: 0.0042 - acc: 1.00 - ETA: 28s - loss: 0.0041 - acc: 1.00 - ETA: 27s - loss: 0.0040 - acc: 1.00 - ETA: 26s - loss: 0.0042 - acc: 1.00 - ETA: 26s - loss: 0.0041 - acc: 1.00 - ETA: 25s - loss: 0.0040 - acc: 1.00 - ETA: 25s - loss: 0.0040 - acc: 1.00 - ETA: 24s - loss: 0.0039 - acc: 1.00 - ETA: 23s - loss: 0.0038 - acc: 1.00 - ETA: 23s - loss: 0.0040 - acc: 1.00 - ETA: 22s - loss: 0.0039 - acc: 1.00 - ETA: 22s - loss: 0.0038 - acc: 1.00 - ETA: 21s - loss: 0.0037 - acc: 1.00 - ETA: 21s - loss: 0.0037 - acc: 1.00 - ETA: 20s - loss: 0.0037 - acc: 1.00 - ETA: 19s - loss: 0.0037 - acc: 1.00 - ETA: 19s - loss: 0.0036 - acc: 1.00 - ETA: 18s - loss: 0.0036 - acc: 1.00 - ETA: 18s - loss: 0.0036 - acc: 1.00 - ETA: 17s - loss: 0.0035 - acc: 1.00 - ETA: 17s - loss: 0.0035 - acc: 1.00 - ETA: 16s - loss: 0.0034 - acc: 1.00 - ETA: 15s - loss: 0.0034 - acc: 1.00 - ETA: 15s - loss: 0.0034 - acc: 1.00 - ETA: 14s - loss: 0.0034 - acc: 1.00 - ETA: 14s - loss: 0.0034 - acc: 1.00 - ETA: 13s - loss: 0.0034 - acc: 1.00 - ETA: 12s - loss: 0.0034 - acc: 1.00 - ETA: 12s - loss: 0.0034 - acc: 1.00 - ETA: 11s - loss: 0.0034 - acc: 1.00 - ETA: 11s - loss: 0.0034 - acc: 1.00 - ETA: 10s - loss: 0.0034 - acc: 1.00 - ETA: 10s - loss: 0.0034 - acc: 1.00 - ETA: 9s - loss: 0.0034 - acc: 1.0000 - ETA: 8s - loss: 0.0034 - acc: 1.000 - ETA: 8s - loss: 0.0034 - acc: 1.000 - ETA: 7s - loss: 0.0033 - acc: 1.000 - ETA: 7s - loss: 0.0033 - acc: 1.000 - ETA: 6s - loss: 0.0033 - acc: 1.000 - ETA: 6s - loss: 0.0033 - acc: 1.000 - ETA: 5s - loss: 0.0034 - acc: 1.000 - ETA: 4s - loss: 0.0033 - acc: 1.000 - ETA: 4s - loss: 0.0033 - acc: 1.000 - ETA: 3s - loss: 0.0033 - acc: 1.000 - ETA: 3s - loss: 0.0035 - acc: 0.999 - ETA: 2s - loss: 0.0035 - acc: 0.999 - ETA: 1s - loss: 0.0034 - acc: 0.999 - ETA: 1s - loss: 0.0034 - acc: 0.999 - ETA: 0s - loss: 0.0034 - acc: 0.999 - 43s 6ms/step - loss: 0.0034 - acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x274a3316898>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs =5,batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qTRzXBYfxjtK",
    "outputId": "a42815b8-6763-438f-b37a-2600afb68e53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7093/7093 [==============================] - ETA: 31 - ETA: 24 - ETA: 21 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 17s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "loss2, acc2 = model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0lYHDWY-NeI"
   },
   "outputs": [],
   "source": [
    "model.save(\"Gesture-model-saved.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Gestures-Training-CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
